{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dBTTgHxd6DC"
   },
   "source": [
    "# 실행 가능성 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3BqU3Xvzd6DG"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1622700356389,
     "user": {
      "displayName": "박태우",
      "photoUrl": "",
      "userId": "14213471907595047482"
     },
     "user_tz": -540
    },
    "id": "J90nnadceSO3",
    "outputId": "11e5ffba-ebbb-4246-d043-895741d4892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86k20mmsd6DI"
   },
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OKTfq1k5d6DI"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "DATASET_PATH = 'dataset/2/'\n",
    "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'\n",
    "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'\n",
    "\n",
    "RESULT_SAVE_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4MREV29d6DJ"
   },
   "source": [
    "## 단순한 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oqmAb6BMd6DJ"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "    return Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)), #tensorflow 버전업으로 코드 변경\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(64, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(128, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(256, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Flatten(),\n",
    "                       Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5Fte1Wqd6DK"
   },
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ked-oqjcd6DK"
   },
   "outputs": [],
   "source": [
    "def preprocess(file_name):\n",
    "    img = tf.io.read_file(file_name)\n",
    "    img = tf.image.decode_png(img, channels=1) #tensorflow 버전업으로 코드 변경\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fnwVUYo4d6DK"
   },
   "outputs": [],
   "source": [
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
    "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
    "\n",
    "ds_ok = ds_ok.map(preprocess)\n",
    "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
    "\n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
    "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
    "\n",
    "ds_fail = ds_fail.map(preprocess)\n",
    "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
    "\n",
    "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqH4BLM0d6DL"
   },
   "source": [
    "## Train, Valid 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "00DeMFYpd6DL"
   },
   "outputs": [],
   "source": [
    "ds_size = len(ok_list) + len(fail_list)\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = ds.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
    "ds_valid = ds.skip(train_size).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, None, None, 1), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2un3AKAd6DL"
   },
   "source": [
    "## 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q9oh7OEHd6DM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471946,
     "status": "ok",
     "timestamp": 1622700888219,
     "user": {
      "displayName": "박태우",
      "photoUrl": "",
      "userId": "14213471907595047482"
     },
     "user_tz": -540
    },
    "id": "Q3en1OOcd6DM",
    "outputId": "00599cf7-e82d-4e72-824d-06bfd733ace9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 61s 2s/step - loss: 0.3212 - accuracy: 0.8991 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 59s 2s/step - loss: 0.3056 - accuracy: 0.9083 - val_loss: 0.2632 - val_accuracy: 0.9145\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 57s 2s/step - loss: 0.2849 - accuracy: 0.9134 - val_loss: 0.2448 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 54s 2s/step - loss: 0.2704 - accuracy: 0.9185 - val_loss: 0.2932 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 55s 2s/step - loss: 0.2677 - accuracy: 0.9134 - val_loss: 0.3137 - val_accuracy: 0.9026\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 54s 2s/step - loss: 0.2908 - accuracy: 0.9062 - val_loss: 0.2638 - val_accuracy: 0.9216\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 55s 2s/step - loss: 0.2618 - accuracy: 0.9134 - val_loss: 0.2565 - val_accuracy: 0.9169\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 57s 2s/step - loss: 0.2597 - accuracy: 0.9195 - val_loss: 0.3545 - val_accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 56s 2s/step - loss: 0.2468 - accuracy: 0.9195 - val_loss: 0.2671 - val_accuracy: 0.9097\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 55s 2s/step - loss: 0.2867 - accuracy: 0.9072 - val_loss: 0.2295 - val_accuracy: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa974bf2208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/10\n",
    "31/31 [==============================] - 61s 2s/step - loss: 0.3212 - accuracy: 0.8991 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
    "Epoch 2/10\n",
    "31/31 [==============================] - 59s 2s/step - loss: 0.3056 - accuracy: 0.9083 - val_loss: 0.2632 - val_accuracy: 0.9145\n",
    "Epoch 3/10\n",
    "31/31 [==============================] - 57s 2s/step - loss: 0.2849 - accuracy: 0.9134 - val_loss: 0.2448 - val_accuracy: 0.9264\n",
    "Epoch 4/10\n",
    "31/31 [==============================] - 54s 2s/step - loss: 0.2704 - accuracy: 0.9185 - val_loss: 0.2932 - val_accuracy: 0.8979\n",
    "Epoch 5/10\n",
    "31/31 [==============================] - 55s 2s/step - loss: 0.2677 - accuracy: 0.9134 - val_loss: 0.3137 - val_accuracy: 0.9026\n",
    "Epoch 6/10\n",
    "31/31 [==============================] - 54s 2s/step - loss: 0.2908 - accuracy: 0.9062 - val_loss: 0.2638 - val_accuracy: 0.9216\n",
    "Epoch 7/10\n",
    "31/31 [==============================] - 55s 2s/step - loss: 0.2618 - accuracy: 0.9134 - val_loss: 0.2565 - val_accuracy: 0.9169\n",
    "Epoch 8/10\n",
    "31/31 [==============================] - 57s 2s/step - loss: 0.2597 - accuracy: 0.9195 - val_loss: 0.3545 - val_accuracy: 0.9026\n",
    "Epoch 9/10\n",
    "31/31 [==============================] - 56s 2s/step - loss: 0.2468 - accuracy: 0.9195 - val_loss: 0.2671 - val_accuracy: 0.9097\n",
    "Epoch 10/10\n",
    "31/31 [==============================] - 55s 2s/step - loss: 0.2867 - accuracy: 0.9072 - val_loss: 0.2295 - val_accuracy: 0.9264\n",
    "<tensorflow.python.keras.callbacks.History at 0x7fa974bf2208>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZreSz-GMd6DO"
   },
   "source": [
    "## 결과를 이미지로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q7TNm2xnd6DO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "#True Positive,Nagative\n",
    "#False Positive,Nagative\n",
    "mkdir(RESULT_SAVE_PATH)\n",
    "mkdir(RESULT_SAVE_PATH + '/TP')\n",
    "mkdir(RESULT_SAVE_PATH + '/TN')\n",
    "mkdir(RESULT_SAVE_PATH + '/FP')\n",
    "mkdir(RESULT_SAVE_PATH + '/FN')\n",
    "\n",
    "index = 0\n",
    "for imgs, labels in ds_valid:\n",
    "    preds = model.predict(imgs)\n",
    "    for idx in range(imgs.shape[0]):\n",
    "        gt = labels[idx].numpy()\n",
    "        y = preds[idx]\n",
    "        \n",
    "        if gt == 1 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/TP'\n",
    "        elif gt == 1 and y <= 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FN'\n",
    "        elif gt == 0 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FP'\n",
    "        else:\n",
    "            path = RESULT_SAVE_PATH + '/TN'\n",
    "            \n",
    "        cv2.imwrite(path + '/%.4f_%04d.png' % (y, index), imgs[idx].numpy() * 255)\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nkIUWvPd6DO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "2.실행 가능성 확인하기.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
