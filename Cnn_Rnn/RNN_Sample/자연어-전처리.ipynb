{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7d29ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
       "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('Dataset/class2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb813f66",
   "metadata": {},
   "source": [
    "# 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f19d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "tissue        0\n",
       "class         0\n",
       "class2        0\n",
       "x             2\n",
       "y             2\n",
       "r             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치 확인\n",
    "#isnull() 멧서드는 결측치를 확인해주고\n",
    "#sum()메서드는 결측치가 몇개인지 합산하여 보여줌\n",
    "df.isnull().sum()\n",
    "#결과는 x y r 각각 2개 씩 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5552adcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0.000000\n",
       "id            0.000000\n",
       "tissue        0.000000\n",
       "class         0.000000\n",
       "class2        0.000000\n",
       "x             0.333333\n",
       "y             0.333333\n",
       "r             0.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치 비율\n",
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328d6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "#모든 행이 NaN일때만 삭제 해주는 dropna\n",
    "df_dropna_all = df.dropna(how='all') #여러가지 사용법이 있으니 자세하게 한번 보셈\n",
    "print(df_dropna_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10361f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "df_dropna_any = df.dropna(how='any') \n",
    "#any는 하나라도 NaN값이 있으면 행을 삭제 결과를 보면 23가 삭제됌\n",
    "print(df_dropna_any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7c837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n",
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    0.0    0.0    0.0\n",
      "3           3  mdb003      C  CIRC      B    0.0    0.0    0.0\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "#fillna는 결측치를 0으로 채우는것\n",
    "df_fillna_0 = df.fillna(0)\n",
    "print(df)\n",
    "print(df_fillna_0)\n",
    "#NaN값이 0으로 채워진것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1eeb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "266.5\n",
      "76.25\n",
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I  500.0    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B  500.0    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "#아까 결측치 확인 시 결측치가 있었던 x,y,r의 평균값을 출력\n",
    "print(df['x'].mean())\n",
    "print(df['y'].mean())\n",
    "print(df['r'].mean())\n",
    "\n",
    "#x,y,r의 결측치를 각각의 평균값으로 채움\n",
    "df['x'].fillna(df['x'].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfac71a",
   "metadata": {},
   "source": [
    "위에서 보다싶이 데이터셋의 결측치를 제거,수정할 수 있는 방법은 여러가지가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d81ed",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab0b95",
   "metadata": {},
   "source": [
    "## nltk사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f355b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For writers, a random sentence can help them get their creative juices flowing.', 'Since the topic of the sentence is completely unknown, it forces the writer to be creative when the sentence appears.', 'There are a number of different ways a writer can use the random sentence for creativity.', 'The most common way to use the sentence is to begin a story.', 'Another option is to include it somewhere in the story.', 'A much more difficult challenge is to use it to end a story.', 'In any of these cases, it forces the writer to think crea']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "text_sample = 'For writers, a random sentence can help them get their creative juices flowing. Since the topic of the sentence is completely unknown, it forces the writer to be creative when the sentence appears. There are a number of different ways a writer can use the random sentence for creativity. The most common way to use the sentence is to begin a story. Another option is to include it somewhere in the story. A much more difficult challenge is to use it to end a story. In any of these cases, it forces the writer to think crea'\n",
    "tokenized_sentences = sent_tokenize(text_sample)\n",
    "print(tokenized_sentences)\n",
    "\n",
    "#정확하게 문장단위로 구분됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0347b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'book', 'is', 'for', 'deep', 'learning', 'learners']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "sentence = \"This book is for deep learning learners\"\n",
    "words = word_tokenize(sentence)\n",
    "print(words)\n",
    "\n",
    "#주어진 문장을 단어단위로 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e71a934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', '`', 's', 'nothing', 'that', 'you', 'don', '`', 't', 'aleady', 'know', 'except', 'most', 'people', 'aren', '`', 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "#아포스트로피가 있는 문장은 nltk의 WordPunctRokenizer을 이용\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "sentence = 'it`s nothing that you don`t aleady know except most people aren`t aware of how their inner world works.'\n",
    "\n",
    "words = WordPunctTokenizer().tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35245e0f",
   "metadata": {},
   "source": [
    "## Keras를 이용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3809fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 's', 'nothing', 'that', 'you', 'don', 't', 'aleady', 'know', 'except', 'most', 'people', 'aren', 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "sentence = 'it`s nothing that you don`t aleady know except most people aren`t aware of how their inner world works.'\n",
    "words = text_to_word_sequence(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7dfd1",
   "metadata": {},
   "source": [
    "## 한글 토큰화 예제(KoNlpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4e94a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##안되서 패스\n",
    "import csv \n",
    "from konlpy.tag import Okt\n",
    "# import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b4318",
   "metadata": {},
   "source": [
    "## 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c4f9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hyunsul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hyunsul/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ad7d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 미적용 : ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pors', 'and', 'conds', 'of', 'any', 'task', 'we', 'perform'] \n",
      "\n",
      "불용어 제거 적용 : ['One', 'first', 'things', 'ask', 'pors', 'conds', 'task', 'perform']\n"
     ]
    }
   ],
   "source": [
    "sample_text = 'One of the first things that we ask ourselves is what are the pors and conds of any task we perform'\n",
    "text_tokens = word_tokenize(sample_text)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "\n",
    "print(f'불용어 제거 미적용 : {text_tokens} \\n')\n",
    "print(f'불용어 제거 적용 : {tokens_without_sw}')\n",
    "\n",
    "#of the 와 같은 단어가 제거된걸 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd7014",
   "metadata": {},
   "source": [
    "## 어간 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04c0e1",
   "metadata": {},
   "source": [
    "### 포터 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2012b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obess obsses\n",
      "standard standard\n",
      "nation nation\n",
      "absent absent\n",
      "tribal tribalic\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(stemmer.stem('obesses'), stemmer.stem('obssesed'))\n",
    "print(stemmer.stem('standardizes'), stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))\n",
    "\n",
    "#실행결과 단어 원형이 비교적 잘 보존되어 있는 것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b0251",
   "metadata": {},
   "source": [
    "### 랭케스터 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "623ddae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obess obsses\n",
      "standard standard\n",
      "nat nat\n",
      "abs abs\n",
      "trib trib\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('obesses'), stemmer.stem('obssesed'))\n",
    "print(stemmer.stem('standardizes'), stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized')) # -- 사전에 없는단어\n",
    "\n",
    "##정밀도가 낮으나 데이터셋을 축소시켜야 하는 특정 상황에서나 유용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648945d1",
   "metadata": {},
   "source": [
    "### 표제어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf6b5a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obess obsses\n",
      "standardizes standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized \n",
      "\n",
      "obesses obssesed\n",
      "standardize standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/hyunsul/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(stemmer.stem('obesses'), stemmer.stem('obssesed'))\n",
    "print(lemma.lemmatize('standardizes'), lemma.lemmatize('standardization'))\n",
    "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
    "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
    "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'),'\\n')\n",
    "\n",
    "##품사 정보를 추가\n",
    "\n",
    "print(lemma.lemmatize('obesses','v'), lemma.lemmatize('obssesed','a'))\n",
    "print(lemma.lemmatize('standardizes','v'), lemma.lemmatize('standardization','n'))\n",
    "print(lemma.lemmatize('national','a'), lemma.lemmatize('nation','n'))\n",
    "print(lemma.lemmatize('absentness','n'), lemma.lemmatize('absently','r'))\n",
    "print(lemma.lemmatize('tribalical','a'), lemma.lemmatize('tribalicalized','v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78410841",
   "metadata": {},
   "source": [
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8db1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f69f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/covtype.csv')\n",
    "x = df[df.columns[:54]]\n",
    "y = df.cover_type #정답 레이블을 cover_type 칼럼으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80f36162",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y , train_size=0.7, random_state=90)\n",
    "\n",
    "#히든레이어 설정\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu',\n",
    "                         input_shape=(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "#아웃풋레이어 설정\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b216070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 406708 samples, validate on 174304 samples\n",
      "Epoch 1/26\n",
      "406708/406708 [==============================] - 26s 63us/sample - loss: 8.2618 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 2/26\n",
      "406708/406708 [==============================] - 25s 60us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 3/26\n",
      "406708/406708 [==============================] - 24s 60us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 4/26\n",
      "406708/406708 [==============================] - 26s 63us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 5/26\n",
      "406708/406708 [==============================] - 27s 66us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 6/26\n",
      "406708/406708 [==============================] - 27s 67us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 7/26\n",
      "406708/406708 [==============================] - 27s 66us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 8/26\n",
      "406708/406708 [==============================] - 27s 66us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 9/26\n",
      "406708/406708 [==============================] - 28s 70us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 10/26\n",
      "406708/406708 [==============================] - 29s 72us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 11/26\n",
      "406708/406708 [==============================] - 28s 70us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 12/26\n",
      "406708/406708 [==============================] - 28s 68us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 13/26\n",
      "406708/406708 [==============================] - 28s 68us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 14/26\n",
      "406708/406708 [==============================] - 30s 73us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 15/26\n",
      "406708/406708 [==============================] - 30s 73us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 16/26\n",
      "406708/406708 [==============================] - 28s 70us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 17/26\n",
      "406708/406708 [==============================] - 29s 72us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 18/26\n",
      "406708/406708 [==============================] - 29s 72us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 19/26\n",
      "406708/406708 [==============================] - 30s 74us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 20/26\n",
      "406708/406708 [==============================] - 30s 73us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 21/26\n",
      "406708/406708 [==============================] - 30s 74us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 22/26\n",
      "406708/406708 [==============================] - 30s 74us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 23/26\n",
      "406708/406708 [==============================] - 28s 69us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 24/26\n",
      "406708/406708 [==============================] - 29s 72us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 25/26\n",
      "406708/406708 [==============================] - 30s 74us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n",
      "Epoch 26/26\n",
      "406708/406708 [==============================] - 28s 69us/sample - loss: 8.2614 - accuracy: 0.4874 - val_loss: 8.2531 - val_accuracy: 0.4880\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=26, batch_size=60,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6bd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
